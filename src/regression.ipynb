{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "from datapipeline import split_data, create_sequences_token\n",
    "import pandas as pd\n",
    "from model import build_transformer_model_regression, build_lstm_model_regression, build_ann_model_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../results/data_row_locks_start_time_pageid-dedupe.csv'\n",
    "# Load the data\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_data = 0.1\n",
    "\n",
    "data = data.iloc[:int(len(data) * percent_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAGEID_int'] = data['PAGEID'].apply(lambda x: int(x.replace(' ', ''))).astype(int)\n",
    "data['ROWID_int'] = data['ROWID'].apply(lambda x: int(x.replace(' ', ''))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAGEID_int'].min(), data['PAGEID_int'].max(), data['PAGEID_int'].mean(), data['PAGEID_int'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAGEID_int'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PAGEID_int_normalized'] = (data['PAGEID_int'] - data['PAGEID_int'].min()) / (data['PAGEID_int'].max() - data['PAGEID_int'].min())\n",
    "data['ROWID_int_normalized'] = (data['ROWID_int'] - data['ROWID_int'].min()) / (data['ROWID_int'].max() - data['ROWID_int'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_min_max_scale(scaled_lst, original_min, original_max):\n",
    "    return np.array([x * (original_max - original_min) + original_min for x in scaled_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['PAGEID_int', 'ROWID_int']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, col, window_size, horizon):\n",
    "    values = df[col]\n",
    "    X_lst = []\n",
    "    y_lst = []\n",
    "    y_naive_lst = []\n",
    "\n",
    "    for i in range(len(values) - window_size - horizon + 1):\n",
    "        X = values.iloc[i : i + window_size].to_numpy()\n",
    "        y = values['PAGEID_int_normalized'].iloc[i + window_size : i + window_size + horizon].to_numpy()\n",
    "        # The naive prediction is the last values (based on horizon) of X to predict the next values\n",
    "        y_naive = values['PAGEID_int_normalized'].iloc[i + window_size - horizon : i + window_size].to_numpy()\n",
    "\n",
    "        X_lst.append(X)\n",
    "        y_lst.append(y)\n",
    "        y_naive_lst.append(y_naive)\n",
    "\n",
    "    X = np.array(X_lst)\n",
    "    y = np.array(y_lst)\n",
    "    y_naive = np.array(y_naive_lst)\n",
    "    return X, y, y_naive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"PAGEID_int_normalized\", \"ROWID_int_normalized\"]].iloc[0:2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_naive = create_sequences(data, [\"PAGEID_int_normalized\"], window_size=50, horizon=1)\n",
    "# X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "# y = y.reshape(y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][-5:], y[0], y_naive[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1][-5:], y[1], y_naive[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive, y_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    x_train,\n",
    "    x_test,\n",
    "    y_train,\n",
    "    y_train_naive,\n",
    "    y_test,\n",
    "    y_test_naive\n",
    ") = split_data(X, y, y_naive, test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.2\n",
    "split_idx = int(len(x_train) * (1 - val_split))\n",
    "x_train, x_val = x_train[:split_idx], x_train[split_idx:]\n",
    "y_train, y_val = y_train[:split_idx], y_train[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, y_train_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape, y_test_naive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_transformer_model_regression(\n",
    "    feature_dim=x_train.shape[-1],\n",
    "    max_length=x_train.shape[1],\n",
    "    horizon=y_train.shape[1],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error'],\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['val_loss'], history.history['val_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_min = data['PAGEID_int'].min()\n",
    "original_max = data['PAGEID_int'].max()\n",
    "# inverse the scaling\n",
    "y_test_unscaled = inverse_min_max_scale(y_test, original_min, original_max)\n",
    "y_pred_unscaled = inverse_min_max_scale(y_pred, original_min, original_max)\n",
    "y_test_naive_unscaled = inverse_min_max_scale(y_test_naive, original_min, original_max)\n",
    "y_test_unscaled[:5], y_pred_unscaled[:5], y_test_naive_unscaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcluate the MAE\n",
    "mae = np.mean(np.abs(y_test_unscaled - y_pred_unscaled))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_naive = np.mean(np.abs(y_test_unscaled - y_test_naive_unscaled))\n",
    "mae_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lstm_model_regression(\n",
    "    feature_dim=x_train.shape[-1],\n",
    "    max_length=x_train.shape[1],\n",
    "    horizon=y_train.shape[1],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error'],\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    ")\n",
    "history.history['val_loss'], history.history['val_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unscaled = inverse_min_max_scale(y_test, original_min, original_max)\n",
    "y_pred_unscaled = inverse_min_max_scale(y_pred, original_min, original_max)\n",
    "y_test_naive_unscaled = inverse_min_max_scale(y_test_naive, original_min, original_max)\n",
    "y_test_unscaled[:5], y_pred_unscaled[:5], y_test_naive_unscaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcluate the MAE\n",
    "mae = np.mean(np.abs(y_test_unscaled - y_pred_unscaled))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_naive = np.mean(np.abs(y_test_unscaled - y_test_naive_unscaled))\n",
    "mae_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_ann_model_regression(\n",
    "    feature_dim=x_train.shape[-1],\n",
    "    max_length=x_train.shape[1],\n",
    "    horizon=y_train.shape[1],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error'],\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    ")\n",
    "history.history['val_loss'], history.history['val_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unscaled = inverse_min_max_scale(y_test, original_min, original_max)\n",
    "y_pred_unscaled = inverse_min_max_scale(y_pred, original_min, original_max)\n",
    "y_test_naive_unscaled = inverse_min_max_scale(y_test_naive, original_min, original_max)\n",
    "y_test_unscaled[:5], y_pred_unscaled[:5], y_test_naive_unscaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcluate the MAE\n",
    "mae = np.mean(np.abs(y_test_unscaled - y_pred_unscaled))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_naive = np.mean(np.abs(y_test_unscaled - y_test_naive_unscaled))\n",
    "mae_naive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
